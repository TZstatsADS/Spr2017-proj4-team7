---
title: "Project 4 - Author Name Disambiguation"
author: "Marie Schiltz"
date: "4/7/2017"
output: pdf_document
---

In this report we will study different methods of **Author Name Disambiguation**. It's the problem of determining whether records in a publications database refer to the same person.

There are two major challenges in author name disambiguation, synonyms and homonyms. In this project we focuses on the second challenge.

We will use domain specific knowledge such as co-aurthors, title of publications and title of journals to perform this task.

The goal of this report is to implement and compare two scientific publications.
(1)  Two supervised learning approaches for name disambiguation in author citations (Han et al. [2004]) - we will study the SVM part of this paper
(2) Author disambiguation using error-driven machine learning with a ranking loss function (Culotta et al. [2007]) - we will study the C/E/Pc part os this paper
Those two papers can be found in the repository under doc/papers

## Step 0: Load Pakages and Functions

```{r}

packages.used=c("stringr", "tex2vec")

# Check packages that need to be installed.
packages.needed=setdiff(packages.used, intersect(installed.packages()[,1], 
                                                 packages.used))

# Install packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE,
                   repos='http://cran.us.r-project.org')
}

# Load packages
library(stringr)
library(text2vec)

# Source Functions
source("../lib/helper_load.R")
```


## Step 1: Load and Process data

The dataset is downloaded from http://clgiles.ist.psu.edu/data/
- There are 14 .txt files in the data folder. Each file is a collection of ambiguous names and associtated citations. e.g. AGupta.txt is the citation files of 26 “A. Gupta”s. The 14 canonical names are top ranked ambiguous names, such as “J. Lee”, “J Smith”, “S. Lee”and “Y. Chen” from the DBLP bibliography.
- The datasets are pre-processed as follows. All the author names in the citations were simpli- fied to first name initial and last name. For example, “Yong-Jik Kim” was simplified to “Y. Kim”. A reason for such simplification is that the first name initial and last name format is popular in citation records. Publication dates are eliminate from citations.
- All citations in the raw data are in the format of
clusterid citationid authors;authors;...<>paper title<>publication venue title, where clusterid indicates the canonical author id.

```{r}
### Dataset - Extract Files' Names
files <- list.files(path = "../data/nameset", pattern = "*.txt")
files <- substr(files, 1, nchar(files)-4)
# Create list of auhtors with good format "F Lastname"
authors <- paste(substring(files, 1, 1), " ", 
                 substring(files, 2, nchar(files)), sep="")

### Upload & Clean Dataset
# Format: Nested List - Upper Level: per homonym - Lower Level: one list per record
# Initialize dataset
dataset <- list(length(files))
for(i in 1:length(files)){
  temp <- as.list(readLines(paste0("../data/nameset/", files[i],".txt")))
  dataset[[i]] <- lapply(temp, clean.record, author=authors[i])
}
```

## Step 2: Implement Paper 1

**Brief Description of the Paper**


```{r}
# Use small dataset to begin with
size <- 2
dataset.small <- list(size)
for(i in 1:size){
  temp <- as.list(readLines(paste0("../data/nameset/", files[i],".txt")))
  dataset.small[[i]] <- lapply(temp, clean.record, author=authors[i])
}
```

Change Format
```{r}
# Change Format - Data Frame
df <- data.frame(matrix(unlist(dataset.small[[1]]), 
                        nrow=length(dataset.small[[1]]), byrow=T), 
                 stringsAsFactors=FALSE)

# Columns' names
names(df) <- c("author.id", "paper.id", "coauthors", "paper", "journal")
```

Create a dtm of unique words
```{r}
it <- itoken(df$paper, 
             preprocessor = tolower, 
             tokenizer = word_tokenizer,
             ids = df$paper.id,
             # turn off progressbar because it won't look nice in rmd
             progressbar = FALSE)
vocab <- create_vocabulary(it, stopwords = c("a", "an", "the", "in", "on",
                                             "at", "of", "above", "under"))
```

Here, we remove pre-defined stopwords, the words like “a”, “the”, “in”, “I”, “you”, “on”, etc, which do not provide much useful information. 

Now that we have a vocabulary list, we can construct a document-term matrix.
```{r}
vectorizer <- vocab_vectorizer(vocab)
dtm <- create_dtm(it, vectorizer)
```

Now we have DTM and can check its dimensions.
```{r}
dim(dtm)
```
As you can see, the DTM has `r nrow(dtm)` rows, equal to the number of citations, and `r ncol(dtm)`, equal to the number of unique terms excluding stopwords.


## Step 3: Implement Paper 2

**Brief Description of the Paper**

## Step 4: Comparison of the two methods

