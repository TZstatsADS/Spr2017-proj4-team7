---
title: "R Notebook"
output: html_notebook
---

## Load Packages
```{r}
if (!require(stringr)) {install.packages(stringr)}
library(stringr)
```

## Organize Data
```{r}
data.lib="../data/nameset"
data.files=list.files(path=data.lib, "*.txt")

data.files

## remove "*.txt"
query.list=substring(data.files, 
                     1, nchar(data.files)-4)

query.list

## add a space
query.list=paste(substring(query.list, 1, 1), 
                 " ", 
                 substring(query.list, 
                           2, nchar(query.list)),
                 sep=""
                 )

query.list

```

```{r}
f.line.proc=function(lin, nam.query="."){

  # remove unwanted characters
  char_notallowed <- "\\@#$%^&?" # characters to be removed
  lin.str=str_replace(lin, char_notallowed, "")

  # get author id
  lin.str=strsplit(lin.str, "_")[[1]]
  author_id=as.numeric(lin.str[1])
  
  # get paper id
  lin.str=lin.str[2]
  paper_id=strsplit(lin.str, " ")[[1]][1]
  lin.str=substring(lin.str, nchar(paper_id)+1, nchar(lin.str))
  paper_id=as.numeric(paper_id)
  
  # get coauthor list
  lin.str=strsplit(lin.str, "<>")[[1]]
  coauthor_list=strsplit(lin.str[1], ";")[[1]]

  #print(lin.str)
  for(j in 1:length(coauthor_list)){
      if(nchar(coauthor_list[j])>0){
        nam = strsplit(coauthor_list[j], " ")[[1]]
        if(nchar(nam[1])>0){
          first.ini=substring(nam[1], 1, 1)
        }else{
          first.ini=substring(nam[2], 1, 1)
        }
      }
      last.name=nam[length(nam)]
      nam.str = paste(first.ini, last.name)
      coauthor_list[j]=nam.str
  }
  
  match_ind = charmatch(nam.query, coauthor_list, nomatch=-1)
  
  #print(nam.query)
  #print(coauthor_list)
  #print(match_ind)
  
  if(match_ind>0){
    
    coauthor_list=coauthor_list[-match_ind]
  }
  
  paper_title=lin.str[2]
  journal_name=lin.str[3]
  
  list(author_id=author_id, 
       paper_id=paper_id, 
       coauthor_list=coauthor_list, 
       paper_title=paper_title, 
       journal_name=journal_name)
}
```

```{r}
data_list=list(1:length(data.files))

for(i in 1:length(data.files)){
  
  ## Step 0 scan in one line at a time.
  
  dat=as.list(readLines(paste(data.lib, data.files[i], sep="/")))
  data_list[[i]]=lapply(dat, f.line.proc, nam.query=query.list[i])
  
  
}
```

## Intersection between coauthor
```{r}
intersection_coauthor <- c()
for (i in 1:577) {
  intersection_coauthor[i] <-length(intersect(data_list[[1]][[1]][3], data_list[[1]][[i]][3]))
}

```
## Intersection between journal name
```{r}
intersection_journal <- c()
for (i in 1:577) {
  intersection_journal[i] <-length(intersect(data_list[[1]][[1]][5], data_list[[1]][[i]][5]))
}

```


## TF-IDF for paper title
```{r}
if (!require(text2vec)) {install.packages("text2vec")}
library(text2vec)

paper_t <- c()
paper_i <- c()
for (i in 1:577) {
  paper_t[i] <- data_list[[1]][[i]][4]
  paper_i[i] <- data_list[[1]][[i]][2]
}
paper_i<- unlist(paper_i)
paper_t<- unlist(paper_t)
it_train <- itoken(paper_t,
  preprocessor = tolower,
  tokenizer = word_tokenizer,
  ids = paper_i,
  
  # turn off progressbar because it won't look nice in rmd
  progressbar = FALSE)

vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))

vocab
```

```{r}
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)

dim(dtm_train)

tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
```

