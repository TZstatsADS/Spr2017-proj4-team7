---
title: "R Notebook"
output:
  html_document: default
  html_notebook: default
---

```{r}
if (!require(stringr)) {install.packages("stringr")}
if (!require(text2vec)) {install.packages("text2vec")}
library(stringr)
library(text2vec)
```

```{r}
data.lib="../data/nameset"
data.files=list.files(path=data.lib, "*.txt")

data.files

## remove "*.txt"
query.list=substring(data.files, 
                     1, nchar(data.files)-4)

query.list

## add a space
query.list=paste(substring(query.list, 1, 1), 
                 " ", 
                 substring(query.list, 
                           2, nchar(query.list)),
                 sep=""
                 )

query.list

```

```{r}
f.line.proc=function(lin, nam.query="."){

  # remove unwanted characters
  char_notallowed <- "\\@#$%^&?" # characters to be removed
  lin.str=str_replace(lin, char_notallowed, "")

  # get author id
  lin.str=strsplit(lin.str, "_")[[1]]
  author_id=as.numeric(lin.str[1])
  
  # get paper id
  lin.str=lin.str[2]
  paper_id=strsplit(lin.str, " ")[[1]][1]
  lin.str=substring(lin.str, nchar(paper_id)+1, nchar(lin.str))
  paper_id=as.numeric(paper_id)
  
  # get coauthor list
  lin.str=strsplit(lin.str, "<>")[[1]]
  coauthor_list=strsplit(lin.str[1], ";")[[1]]

  #print(lin.str)
  for(j in 1:length(coauthor_list)){
      if(nchar(coauthor_list[j])>0){
        nam = strsplit(coauthor_list[j], " ")[[1]]
        if(nchar(nam[1])>0){
          first.ini=substring(nam[1], 1, 1)
        }else{
          first.ini=substring(nam[2], 1, 1)
        }
      }
      last.name=nam[length(nam)]
      nam.str = paste(first.ini, last.name)
      coauthor_list[j]=nam.str
  }
  
  match_ind = charmatch(nam.query, coauthor_list, nomatch=-1)
  
  #print(nam.query)
  #print(coauthor_list)
  #print(match_ind)
  
  if(match_ind>0){
    
    coauthor_list=coauthor_list[-match_ind]
  }
  
  paper_title=lin.str[2]
  journal_name=lin.str[3]
  
  list(author_id=author_id, 
       paper_id=paper_id, 
       coauthor_list=coauthor_list, 
       paper_title=paper_title, 
       journal_name=journal_name)
}
```

```{r}
data_list=list(1:length(data.files))

for(i in 1:length(data.files)){
  
  ## Step 0 scan in one line at a time.
  
  dat=as.list(readLines(paste(data.lib, data.files[i], sep="/")))
  data_list[[i]]=lapply(dat, f.line.proc, nam.query=query.list[i])
  
  
}
```

## Coauthor Features
```{r}
coauthor <- c()
for (i in 1:577) {
  coauthor[i] <- data_list[[1]][[i]][3]
}

unique_coauthor <- unique(unlist(coauthor))

feature_coauthor <- matrix(nrow = 577,ncol = length(unique_coauthor))
for (i in 1:577) {
  for (j in 1:length(unique_coauthor)) {
    feature_coauthor[i,j] <- length(intersect(unlist(data_list[[1]][[i]][3]),unique_coauthor[j]))
  }
}

feature_coauthor <- data.frame(feature_coauthor)
```


## Journal Features
```{r}
journal <- c()
for (i in 1:577) {
  journal[i] <- data_list[[1]][[i]][5]
}

unique_journal <- unique(unlist(journal))

feature_journal <- matrix(nrow = 577,ncol = length(unique_journal))
for (i in 1:577) {
  for (j in 1:length(unique_journal)) {
    feature_journal[i,j] <- length(intersect(unlist(data_list[[1]][[i]][5]),unique_journal[j]))
  }
}

feature_journal <- data.frame(feature_journal)


```

## Paper Title Feature
```{r}
AKumar <- data.frame(scan("../data/nameset/AKumar.txt",what = list(Coauthor = "", Paper = "", Journal = ""),
                     sep=">", quiet=TRUE),stringsAsFactors=FALSE)
# This need to be modified for different name set
# extract canonical author id befor "_"
AKumar$AuthorID <- sub("_.*","",AKumar$Coauthor)
# extract paper number under same author between "_" and first whitespace
AKumar$PaperNO <- sub(".*_(\\w*)\\s.*", "\\1", AKumar$Coauthor)
# delete "<" in AKumar$Coauthor, you may need to further process the coauthor
# term depending on the method you are using
AKumar$Coauthor <- gsub("<","",sub("^.*?\\s","", AKumar$Coauthor))
# delete "<" in AKumar$Paper
AKumar$Paper <- gsub("<","",AKumar$Paper)
# add PaperID for furthur use, you may want to combine all the nameset files and
# then assign the unique ID for all the citations
AKumar$PaperID <- rownames(AKumar)
```

```{r}
it_train <- itoken(AKumar$Paper,
preprocessor = tolower,
tokenizer = word_tokenizer,
ids = AKumar$PaperID,
# turn off progressbar because it won't look nice in rmd
progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
"at", "of", "above", "under"))
vocab
```

```{r}
vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)
tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
dtm_train_tfidf
```

